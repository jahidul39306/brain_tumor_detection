{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":7435625,"sourceType":"datasetVersion","datasetId":4327413}],"dockerImageVersionId":30647,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport torchvision\nimport torch\nimport numpy as np\n\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\n# torch.manual_seed(0)\n\nprint('Torch version: ', torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-02-14T15:11:57.313874Z","iopub.execute_input":"2024-02-14T15:11:57.314101Z","iopub.status.idle":"2024-02-14T15:12:23.573844Z","shell.execute_reply.started":"2024-02-14T15:11:57.314066Z","shell.execute_reply":"2024-02-14T15:12:23.572825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(image_dir):\n            images = []\n            labels = []\n\n            for filename in os.listdir(os.path.join(image_dir, \"images\")):\n                if filename.endswith('.jpg'):\n                    img_path = os.path.join(image_dir, \"images\", filename)\n                    label_path = os.path.join(image_dir, \"labels\", filename.replace('.jpg', '.txt'))\n\n                    with open(label_path, 'r') as label_file:\n                        line = label_file.readline().strip()\n                        if not line:\n                            continue\n\n                        label = int(line.split()[0])\n                        labels.append(label)\n\n                images.append(filename)\n\n            return images, labels\n        \ndataset_dir = '/kaggle/input/medical-image-dataset-brain-tumor-detection/Brain Tumor Detection/train'\n\n# Load the data\nimages, labels = load_data(dataset_dir)\nnum_classes = len(np.unique(labels))\nnum_classes","metadata":{"execution":{"iopub.status.busy":"2024-02-14T15:26:36.625373Z","iopub.execute_input":"2024-02-14T15:26:36.625711Z","iopub.status.idle":"2024-02-14T15:26:42.680510Z","shell.execute_reply.started":"2024-02-14T15:26:36.625684Z","shell.execute_reply":"2024-02-14T15:26:42.679778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating custom dataset","metadata":{}},{"cell_type":"code","source":"class BrainTumorDataset(torch.utils.data.Dataset):\n    def __init__(self, image_dir, transform=None):\n        def load_data(image_dir):\n            images = []\n            labels = []\n\n            for filename in os.listdir(os.path.join(image_dir, \"images\")):\n                if filename.endswith('.jpg'):\n                    img_path = os.path.join(image_dir, \"images\", filename)\n                    label_path = os.path.join(image_dir, \"labels\", filename.replace('.jpg', '.txt'))\n\n                    with open(label_path, 'r') as label_file:\n                        line = label_file.readline().strip()\n                        if not line:\n                            continue\n\n                        label = int(line.split()[0])\n                        labels.append(label)\n\n                images.append(filename)\n\n            return images, labels\n        \n        self.image_dir = image_dir\n        self.images, self.labels = load_data(self.image_dir)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.images)\n        \n    def __getitem__(self, index):\n        image_path = os.path.join(self.image_dir, \"images\", self.images[index])\n        image = Image.open(image_path).convert('RGB')\n        return self.transform(image), self.labels[index]","metadata":{"execution":{"iopub.status.busy":"2024-02-14T15:12:23.575455Z","iopub.execute_input":"2024-02-14T15:12:23.575999Z","iopub.status.idle":"2024-02-14T15:12:23.583703Z","shell.execute_reply.started":"2024-02-14T15:12:23.575968Z","shell.execute_reply":"2024-02-14T15:12:23.582888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image transformation","metadata":{}},{"cell_type":"code","source":"train_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size=(224, 224)),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-02-14T15:12:23.584729Z","iopub.execute_input":"2024-02-14T15:12:23.584974Z","iopub.status.idle":"2024-02-14T15:12:23.596337Z","shell.execute_reply.started":"2024-02-14T15:12:23.584951Z","shell.execute_reply":"2024-02-14T15:12:23.595588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size=(224, 224)),\n    torchvision.transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-02-14T15:12:23.598055Z","iopub.execute_input":"2024-02-14T15:12:23.598299Z","iopub.status.idle":"2024-02-14T15:12:23.605991Z","shell.execute_reply.started":"2024-02-14T15:12:23.598275Z","shell.execute_reply":"2024-02-14T15:12:23.605316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare dataloader","metadata":{}},{"cell_type":"code","source":"train_dir = '/kaggle/input/medical-image-dataset-brain-tumor-detection/Brain Tumor Detection/train'\ntrain_dataset = BrainTumorDataset(train_dir, transform=train_transform)","metadata":{"execution":{"iopub.status.busy":"2024-02-14T15:12:23.606780Z","iopub.execute_input":"2024-02-14T15:12:23.607022Z","iopub.status.idle":"2024-02-14T15:13:02.413694Z","shell.execute_reply.started":"2024-02-14T15:12:23.606982Z","shell.execute_reply":"2024-02-14T15:13:02.412944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_dir = '/kaggle/input/medical-image-dataset-brain-tumor-detection/Brain Tumor Detection/valid'\nvalid_dataset = BrainTumorDataset(valid_dir, transform=test_transform)\n\ntest_dir = '/kaggle/input/medical-image-dataset-brain-tumor-detection/Brain Tumor Detection/test'\ntest_dataset = BrainTumorDataset(test_dir, transform=test_transform)","metadata":{"execution":{"iopub.status.busy":"2024-02-14T15:13:02.414721Z","iopub.execute_input":"2024-02-14T15:13:02.414976Z","iopub.status.idle":"2024-02-14T15:13:20.197552Z","shell.execute_reply.started":"2024-02-14T15:13:02.414951Z","shell.execute_reply":"2024-02-14T15:13:20.196722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of training examples: ', len(train_dataset))\nprint('Number of validation examples: ', len(valid_dataset))\nprint('Number of testing examples: ', len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-02-14T15:13:20.198525Z","iopub.execute_input":"2024-02-14T15:13:20.198791Z","iopub.status.idle":"2024-02-14T15:13:20.202932Z","shell.execute_reply.started":"2024-02-14T15:13:20.198763Z","shell.execute_reply":"2024-02-14T15:13:20.202342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\n\ndl_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ndl_valid = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\ndl_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n\nprint('Number of training batches: ', len(dl_train))\nprint('Number of validation batches: ', len(dl_valid))\nprint('Number of testing batches: ', len(dl_test))","metadata":{"execution":{"iopub.status.busy":"2024-02-14T16:15:02.925695Z","iopub.execute_input":"2024-02-14T16:15:02.926236Z","iopub.status.idle":"2024-02-14T16:15:02.931937Z","shell.execute_reply.started":"2024-02-14T16:15:02.926205Z","shell.execute_reply":"2024-02-14T16:15:02.931329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data visualization","metadata":{}},{"cell_type":"code","source":"def show_images(images, labels, preds):\n    plt.figure(figsize=(10, 7))\n    for i, image in enumerate(images):\n        plt.subplot(1, 5, i+1, xticks=[], yticks=[])\n        image = image.numpy().transpose((1, 2, 0))\n        image = np.clip(image, 0., 1.)\n        plt.imshow(image)\n        \n        col = 'green' if preds[i] == labels[i] else 'red'\n        plt.xlabel(f'Tumor' if labels[i] else 'Non-Tumor')\n        plt.ylabel(f'Tumor' if preds[i] else 'Non-Tumor', color=col)\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T16:15:05.661873Z","iopub.execute_input":"2024-02-14T16:15:05.662206Z","iopub.status.idle":"2024-02-14T16:15:05.668195Z","shell.execute_reply.started":"2024-02-14T16:15:05.662179Z","shell.execute_reply":"2024-02-14T16:15:05.667406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(iter(dl_train))\nshow_images(images[:5], labels[:5], labels[:5])","metadata":{"execution":{"iopub.status.busy":"2024-02-14T16:15:05.977566Z","iopub.execute_input":"2024-02-14T16:15:05.977839Z","iopub.status.idle":"2024-02-14T16:15:06.595915Z","shell.execute_reply.started":"2024-02-14T16:15:05.977798Z","shell.execute_reply":"2024-02-14T16:15:06.594860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating model","metadata":{}},{"cell_type":"code","source":"model = torchvision.models.resnet18(weights=True)\nfor param in model.parameters():\n    param.requires_grad = False\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-02-14T16:15:06.597276Z","iopub.execute_input":"2024-02-14T16:15:06.597546Z","iopub.status.idle":"2024-02-14T16:15:06.793358Z","shell.execute_reply.started":"2024-02-14T16:15:06.597515Z","shell.execute_reply":"2024-02-14T16:15:06.792512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fc = torch.nn.Linear(in_features=512, out_features=num_classes)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-02-14T16:29:25.026904Z","iopub.execute_input":"2024-02-14T16:29:25.027303Z","iopub.status.idle":"2024-02-14T16:29:25.033727Z","shell.execute_reply.started":"2024-02-14T16:29:25.027274Z","shell.execute_reply":"2024-02-14T16:29:25.032848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_preds():\n    model.eval()\n    images, labels = next(iter(dl_test))\n    outputs = model(images)\n    _, preds = torch.max(outputs, 1)\n    show_images(images[:5], labels[:5], preds[:5])","metadata":{"execution":{"iopub.status.busy":"2024-02-14T16:29:25.860273Z","iopub.execute_input":"2024-02-14T16:29:25.860683Z","iopub.status.idle":"2024-02-14T16:29:25.866416Z","shell.execute_reply.started":"2024-02-14T16:29:25.860647Z","shell.execute_reply":"2024-02-14T16:29:25.865411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_preds()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T16:29:25.938610Z","iopub.execute_input":"2024-02-14T16:29:25.939273Z","iopub.status.idle":"2024-02-14T16:29:26.935291Z","shell.execute_reply.started":"2024-02-14T16:29:25.939231Z","shell.execute_reply":"2024-02-14T16:29:26.934481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Traing the model","metadata":{}},{"cell_type":"code","source":"def train(epochs):\n    print('Training start...')\n    for e in range(0, epochs):\n        print('='*40)\n        print(f'Starting epoch {e + 1}/{epochs}')\n        print('='*40)\n        \n        train_loss = 0\n        val_loss = 0\n        train_loss_list = []\n        val_loss_list = []\n        acc_list = []\n        \n        model.train()\n        \n        for train_step, (images, labels) in enumerate(dl_train):\n#             images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss_list.append(loss.item())\n            train_loss += loss.item()\n            \n            if train_step % 20 == 0:\n                print('Evaluating at step ', train_step)\n                acc = 0\n                \n                model.eval()\n                \n                for val_step, (images, labels) in enumerate(dl_valid):\n#                     images, labels = images.to(device), labels.to(device)\n                    outputs = model(images)\n                    loss = loss_fn(outputs, labels)\n                    val_loss_list.append(loss.item())\n                    val_loss += loss.item()\n                    \n                    _, preds = torch.max(outputs, 1)\n                    acc += sum((preds == labels).numpy())\n                \n                val_loss /= (val_step + 1)\n                acc = acc / len(valid_dataset)\n                acc_list.append(acc)\n                print(f'Val loss: {val_loss:.4f}, Acc: {acc:.4f}')\n                show_preds()\n                \n                model.train()\n                \n                if acc >= 0.95:\n                    print('Performance achieved')\n                    return\n        train_loss /= (train_step + 1)\n        print(f'Training loss: {train_loss:.4f}')\n    print('Training complete')\n    return train_loss_list, val_loss_list, acc_list","metadata":{"execution":{"iopub.status.busy":"2024-02-14T16:50:38.629907Z","iopub.execute_input":"2024-02-14T16:50:38.630271Z","iopub.status.idle":"2024-02-14T16:50:38.639321Z","shell.execute_reply.started":"2024-02-14T16:50:38.630243Z","shell.execute_reply":"2024-02-14T16:50:38.638702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# print(\"the device type is\", device)\n# resnet18 = resnet18.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-14T16:50:39.589740Z","iopub.execute_input":"2024-02-14T16:50:39.590060Z","iopub.status.idle":"2024-02-14T16:50:39.593492Z","shell.execute_reply.started":"2024-02-14T16:50:39.590033Z","shell.execute_reply":"2024-02-14T16:50:39.592789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss, val_loss, acc = train(epochs=6)","metadata":{"execution":{"iopub.status.busy":"2024-02-14T16:50:39.890971Z","iopub.execute_input":"2024-02-14T16:50:39.891343Z","iopub.status.idle":"2024-02-14T16:57:42.845516Z","shell.execute_reply.started":"2024-02-14T16:50:39.891295Z","shell.execute_reply":"2024-02-14T16:57:42.844679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}